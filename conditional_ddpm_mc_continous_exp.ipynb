{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import gymnasium as gym\n",
    "import csv\n",
    "import time\n",
    "from gym.wrappers import RecordVideo\n",
    "\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalDiffusionNet(nn.Module):\n",
    "    def __init__(self,data_dim,cond_dim):\n",
    "        super(ConditionalDiffusionNet,self).__init__()\n",
    "        n_unit = 256\n",
    "\n",
    "        self.l1 = nn.Linear(data_dim, n_unit)\n",
    "        self.l2 = nn.Linear(n_unit, n_unit)\n",
    "\n",
    "        self.l1_beta = nn.Linear(1, n_unit)\n",
    "        self.l2_beta = nn.Linear(n_unit, n_unit)\n",
    "\n",
    "        self.l1_cond = nn.Linear(cond_dim, n_unit)\n",
    "        self.l2_cond = nn.Linear(n_unit, n_unit)\n",
    "\n",
    "        self.l3 = nn.Linear(n_unit,n_unit)\n",
    "        self.l4 = nn.Linear(n_unit,data_dim)\n",
    "    \n",
    "    def forward(self,x,c,t):\n",
    "        xx = self.l1(x)\n",
    "        xx = F.relu(xx)\n",
    "        xx = self.l2(xx)\n",
    "        xx = F.relu(xx)\n",
    "\n",
    "        cc = self.l1_cond(c)\n",
    "        cc = F.relu(cc)\n",
    "        cc = self.l2_cond(cc)\n",
    "        cc = F.relu(cc)\n",
    "\n",
    "        bb = self.l1_beta(t)\n",
    "        bb = F.relu(bb)\n",
    "        bb = self.l2_beta(bb)\n",
    "        bb = F.relu(bb)\n",
    "\n",
    "        xx = self.l3(xx+bb+cc)\n",
    "        xx = F.relu(xx)\n",
    "        xx = self.l4(xx)\n",
    "\n",
    "        return xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalDenoisingDiffusionProbabilisticModel():\n",
    "    def __init__(self, X, cond, beta, device, batch_size=32):\n",
    "        self.device = device\n",
    "\n",
    "        self.X = X\n",
    "        self.x_dim = self.X.shape[1]\n",
    "        self.C = cond\n",
    "        self.c_dim = self.C.shape[1]\n",
    "        self.beta = beta\n",
    "        self.n_beta = self.beta.shape[0]\n",
    "\n",
    "        alpha = 1 - self.beta\n",
    "        self.alpha = torch.tensor([[torch.prod(alpha[:i+1])] for i in range(self.n_beta)]).float()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.model = ConditionalDiffusionNet(self.X.shape[1], self.C.shape[1]).to(self.device)\n",
    "\n",
    "        train_dataset = torch.utils.data.TensorDataset(self.X, self.C)\n",
    "        self.train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=1e-5)\n",
    "\n",
    "\n",
    "\n",
    "    def learning(self, n_epoch=10):\n",
    "        self.model.train()\n",
    "\n",
    "        for e in range(n_epoch):\n",
    "            for (x_batch, c_batch) in self.train_loader:\n",
    "                loss_hist = []\n",
    "\n",
    "                x_batch = x_batch\n",
    "                c_batch = c_batch\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                t = torch.randint(low=0, high=self.n_beta, size=(x_batch.shape[0],))\n",
    "                noise = torch.randn(x_batch.shape[0], self.x_dim)\n",
    "\n",
    "\n",
    "                x_t = torch.sqrt(self.alpha[t]) * x_batch + torch.sqrt(1-self.alpha[t]) * noise\n",
    "\n",
    "                noise_pred = self.model(x_t.to(self.device),\n",
    "                                        c_batch.to(self.device),\n",
    "                                        t[:,None].float().to(self.device))\n",
    "\n",
    "\n",
    "                # import ipdb; ipdb.set_trace()\n",
    "                loss = ((noise_pred - noise.to(device))**2).sum()\n",
    "                loss_hist.append(loss.detach().cpu().numpy()/x_batch.shape[0])\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "                self.optimizer.step()\n",
    "\n",
    "            print('epoch: {}, loss: {}'.format(e, np.array(loss_hist).mean()))\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "\n",
    "\n",
    "    def sampling(self, c, n=100):\n",
    "        x_sample = torch.randn(n, self.x_dim)\n",
    "        c_sample = c.repeat(n, 1)\n",
    "\n",
    "        for t in range(self.n_beta)[::-1]:\n",
    "            noise = torch.randn(n, self.x_dim)\n",
    "            if t==0: noise= torch.zeros(n, self.x_dim)\n",
    "\n",
    "            sigma = torch.sqrt(self.beta[t]*(1-self.alpha[t-1])/(1-self.alpha[t]))\n",
    "\n",
    "            noise_pred = self.model(x_sample.to(self.device),\n",
    "                                    c_sample.to(self.device),\n",
    "                                    torch.tensor([[t]]).float().to(self.device)).detach().cpu()\n",
    "\n",
    "            # import ipdb;ipdb.set_trace()\n",
    "            x_sample = (x_sample - self.beta[t]*noise_pred/torch.sqrt(1-self.alpha[t])) / torch.sqrt(1-self.beta[t]) + sigma * noise\n",
    "\n",
    "\n",
    "        return x_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'combined_big_random_expert_trajectory.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# extraction: timestamp, action, position, velocity\n",
    "x = data['action'].values[:,None]\n",
    "c = data[['position', 'velocity']].values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 2.170483430226644\n",
      "epoch: 1, loss: 0.43773770332336426\n",
      "epoch: 2, loss: 0.35216307640075684\n",
      "epoch: 3, loss: 0.2119075059890747\n",
      "epoch: 4, loss: 0.4817020893096924\n",
      "epoch: 5, loss: 0.13639485836029053\n",
      "epoch: 6, loss: 0.235132098197937\n",
      "epoch: 7, loss: 0.312742014726003\n",
      "epoch: 8, loss: 0.4238012234369914\n",
      "epoch: 9, loss: 0.6956948439280192\n",
      "epoch: 10, loss: 0.3484635353088379\n",
      "epoch: 11, loss: 0.2309399644533793\n",
      "epoch: 12, loss: 0.0660000095764796\n",
      "epoch: 13, loss: 0.13474772373835245\n",
      "epoch: 14, loss: 0.14422144492467245\n",
      "epoch: 15, loss: 0.7540886402130127\n",
      "epoch: 16, loss: 0.11228170990943909\n",
      "epoch: 17, loss: 0.0944407085577647\n",
      "epoch: 18, loss: 0.04526785512765249\n",
      "epoch: 19, loss: 0.09148130814234416\n",
      "epoch: 20, loss: 0.30289846658706665\n",
      "epoch: 21, loss: 0.2381031115849813\n",
      "epoch: 22, loss: 0.1353696584701538\n",
      "epoch: 23, loss: 1.3296154340108235\n",
      "epoch: 24, loss: 0.0972101887067159\n",
      "epoch: 25, loss: 0.2705947955449422\n",
      "epoch: 26, loss: 0.4341728687286377\n",
      "epoch: 27, loss: 0.11799689133961995\n",
      "epoch: 28, loss: 0.29583774010340375\n",
      "epoch: 29, loss: 0.07622607549031575\n",
      "epoch: 30, loss: 0.421831210454305\n",
      "epoch: 31, loss: 0.11566189924875896\n",
      "epoch: 32, loss: 0.05929634968439738\n",
      "epoch: 33, loss: 0.06334474682807922\n",
      "epoch: 34, loss: 0.3238351345062256\n",
      "epoch: 35, loss: 0.400454044342041\n",
      "epoch: 36, loss: 0.07739162941773732\n",
      "epoch: 37, loss: 0.01235534499088923\n",
      "epoch: 38, loss: 0.14030317465464273\n",
      "epoch: 39, loss: 0.11846953630447388\n",
      "epoch: 40, loss: 0.056668867667516075\n",
      "epoch: 41, loss: 0.14102429151535034\n",
      "epoch: 42, loss: 0.038758342464764915\n",
      "epoch: 43, loss: 0.9449116388956705\n",
      "epoch: 44, loss: 0.10375736157099406\n",
      "epoch: 45, loss: 0.3735179503758748\n",
      "epoch: 46, loss: 0.6795530319213867\n",
      "epoch: 47, loss: 0.22214976946512857\n",
      "epoch: 48, loss: 0.3270966609319051\n",
      "epoch: 49, loss: 0.312392254670461\n",
      "epoch: 50, loss: 0.36273733774820965\n",
      "epoch: 51, loss: 0.1822387377421061\n",
      "epoch: 52, loss: 0.6801683108011881\n",
      "epoch: 53, loss: 0.07380810379981995\n",
      "epoch: 54, loss: 0.03246729572614034\n",
      "epoch: 55, loss: 0.41112009684244794\n",
      "epoch: 56, loss: 0.10304272174835205\n",
      "epoch: 57, loss: 0.29628247022628784\n",
      "epoch: 58, loss: 0.2693915367126465\n",
      "epoch: 59, loss: 0.03504901876052221\n",
      "epoch: 60, loss: 0.0838911235332489\n",
      "epoch: 61, loss: 0.7228463490804037\n",
      "epoch: 62, loss: 0.09596885244051616\n",
      "epoch: 63, loss: 0.2645261486371358\n",
      "epoch: 64, loss: 0.38592779636383057\n",
      "epoch: 65, loss: 0.9230262438456217\n",
      "epoch: 66, loss: 0.5745193163553873\n",
      "epoch: 67, loss: 0.033645970125993095\n",
      "epoch: 68, loss: 0.4548269907633464\n",
      "epoch: 69, loss: 0.25472225745519\n",
      "epoch: 70, loss: 0.200709859530131\n",
      "epoch: 71, loss: 0.4793713887532552\n",
      "epoch: 72, loss: 0.05030242105325063\n",
      "epoch: 73, loss: 0.40983780225118\n",
      "epoch: 74, loss: 0.3905375003814697\n",
      "epoch: 75, loss: 0.08680448929468791\n",
      "epoch: 76, loss: 0.2767711679140727\n",
      "epoch: 77, loss: 0.6257532437642416\n",
      "epoch: 78, loss: 0.03474774956703186\n",
      "epoch: 79, loss: 0.07410054405530293\n",
      "epoch: 80, loss: 0.15966013073921204\n",
      "epoch: 81, loss: 0.2851872444152832\n",
      "epoch: 82, loss: 0.47203683853149414\n",
      "epoch: 83, loss: 0.05527040362358093\n",
      "epoch: 84, loss: 0.17705810070037842\n",
      "epoch: 85, loss: 0.04588481287161509\n",
      "epoch: 86, loss: 0.35393857955932617\n",
      "epoch: 87, loss: 0.4543011983235677\n",
      "epoch: 88, loss: 0.18402079741160074\n",
      "epoch: 89, loss: 0.27159146467844647\n",
      "epoch: 90, loss: 0.09949316581090291\n",
      "epoch: 91, loss: 0.15549118320147196\n",
      "epoch: 92, loss: 0.11250550548235576\n",
      "epoch: 93, loss: 0.04042960951725642\n",
      "epoch: 94, loss: 1.1184450785319011\n",
      "epoch: 95, loss: 0.025038046141465504\n",
      "epoch: 96, loss: 0.28229133288065594\n",
      "epoch: 97, loss: 0.08603709936141968\n",
      "epoch: 98, loss: 0.4230685234069824\n",
      "epoch: 99, loss: 0.05109362304210663\n"
     ]
    }
   ],
   "source": [
    "beta = np.exp(np.linspace(np.log(0.001), np.log(0.9), 300))\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "ddpm = ConditionalDenoisingDiffusionProbabilisticModel(\n",
    "                torch.tensor(x).float(),\n",
    "                torch.tensor(c).float(),\n",
    "                torch.tensor(beta).float(), device, batch_size=32)\n",
    "\n",
    "ddpm.learning(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_execute(env, ddpm, device, n_steps, output_file = 'execution_log.csv'):\n",
    "    # observation from gym evironment\n",
    "    observation, _ = env.reset()\n",
    "\n",
    "    # initialize a dataframe to log the data\n",
    "    log_data =[]\n",
    "\n",
    "    for step in range(n_steps):\n",
    "        position = observation[0]\n",
    "        velocity = observation[1]\n",
    "\n",
    "        c_tensor = torch.tensor([[position, velocity]], dtype = torch.float32).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            action_tensor = ddpm.sampling(c_tensor)\n",
    "        \n",
    "        action = action_tensor.cpu().numpy().flatten()\n",
    "\n",
    "        # execute action in the environment\n",
    "        observation, reward, done,_,_ = env.step(action)\n",
    "\n",
    "        env.render()\n",
    "\n",
    "        timestamp = time.time()\n",
    "\n",
    "        # log data into csv file\n",
    "        log_data.append({'timestamp':timestamp, 'action':action[0], 'position':position, 'velocity': velocity})\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "        time.sleep(0.1)\n",
    "    \n",
    "    log_df = pd.DataFrame(log_data)\n",
    "    log_df.to_csv(output_file , index = False)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    env = gym.make('MountainCarContinuous-v0', render_mode=\"human\")\n",
    "    ddpm = ConditionalDenoisingDiffusionProbabilisticModel(torch.tensor(x).float(),\n",
    "                torch.tensor(c).float(),\n",
    "                torch.tensor(beta).float(), device, batch_size=32)\n",
    "    predict_and_execute(env,ddpm, device, n_steps=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dif_aug_cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
