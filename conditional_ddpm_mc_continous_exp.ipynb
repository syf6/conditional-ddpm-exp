{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import gymnasium as gym\n",
    "import csv\n",
    "import time\n",
    "from gym.wrappers import RecordVideo\n",
    "\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalDiffusionNet(nn.Module):\n",
    "    def __init__(self,data_dim,cond_dim):\n",
    "        super(ConditionalDiffusionNet,self).__init__()\n",
    "        n_unit = 256\n",
    "\n",
    "        self.l1 = nn.Linear(data_dim, n_unit)\n",
    "        self.l2 = nn.Linear(n_unit, n_unit)\n",
    "\n",
    "        self.l1_beta = nn.Linear(1, n_unit)\n",
    "        self.l2_beta = nn.Linear(n_unit, n_unit)\n",
    "\n",
    "        self.l1_cond = nn.Linear(cond_dim, n_unit)\n",
    "        self.l2_cond = nn.Linear(n_unit, n_unit)\n",
    "\n",
    "        self.l3 = nn.Linear(n_unit,n_unit)\n",
    "        self.l4 = nn.Linear(n_unit,data_dim)\n",
    "    \n",
    "    def forward(self,x,c,t):\n",
    "        xx = self.l1(x)\n",
    "        xx = F.relu(xx)\n",
    "        xx = self.l2(xx)\n",
    "        xx = F.relu(xx)\n",
    "\n",
    "        cc = self.l1_cond(c)\n",
    "        cc = F.relu(cc)\n",
    "        cc = self.l2_cond(cc)\n",
    "        cc = F.relu(cc)\n",
    "\n",
    "        bb = self.l1_beta(t)\n",
    "        bb = F.relu(bb)\n",
    "        bb = self.l2_beta(bb)\n",
    "        bb = F.relu(bb)\n",
    "\n",
    "        xx = self.l3(xx+bb+cc)\n",
    "        xx = F.relu(xx)\n",
    "        xx = self.l4(xx)\n",
    "\n",
    "        return xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalDenoisingDiffusionProbabilisticModel():\n",
    "    def __init__(self, X, cond, beta, device, batch_size=32):\n",
    "        self.device = device\n",
    "\n",
    "        self.X = X\n",
    "        self.x_dim = self.X.shape[1]\n",
    "        self.C = cond\n",
    "        self.c_dim = self.C.shape[1]\n",
    "        self.beta = beta\n",
    "        self.n_beta = self.beta.shape[0]\n",
    "\n",
    "        alpha = 1 - self.beta\n",
    "        self.alpha = torch.tensor([[torch.prod(alpha[:i+1])] for i in range(self.n_beta)]).float()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.model = ConditionalDiffusionNet(self.X.shape[1], self.C.shape[1]).to(self.device)\n",
    "\n",
    "        train_dataset = torch.utils.data.TensorDataset(self.X, self.C)\n",
    "        self.train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=1e-5)\n",
    "\n",
    "\n",
    "\n",
    "    def learning(self, n_epoch=10):\n",
    "        self.model.train()\n",
    "\n",
    "        for e in range(n_epoch):\n",
    "            for (x_batch, c_batch) in self.train_loader:\n",
    "                loss_hist = []\n",
    "\n",
    "                x_batch = x_batch\n",
    "                c_batch = c_batch\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                t = torch.randint(low=0, high=self.n_beta, size=(x_batch.shape[0],))\n",
    "                noise = torch.randn(x_batch.shape[0], self.x_dim)\n",
    "\n",
    "\n",
    "                x_t = torch.sqrt(self.alpha[t]) * x_batch + torch.sqrt(1-self.alpha[t]) * noise\n",
    "\n",
    "                noise_pred = self.model(x_t.to(self.device),\n",
    "                                        c_batch.to(self.device),\n",
    "                                        t[:,None].float().to(self.device))\n",
    "\n",
    "\n",
    "                # import ipdb; ipdb.set_trace()\n",
    "                loss = ((noise_pred - noise.to(device))**2).sum()\n",
    "                loss_hist.append(loss.detach().cpu().numpy()/x_batch.shape[0])\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "                self.optimizer.step()\n",
    "\n",
    "            print('epoch: {}, loss: {}'.format(e, np.array(loss_hist).mean()))\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "\n",
    "\n",
    "    def sampling(self, c, n=100):\n",
    "        x_sample = torch.randn(n, self.x_dim)\n",
    "        c_sample = c.repeat(n, 1)\n",
    "\n",
    "        for t in range(self.n_beta)[::-1]:\n",
    "            noise = torch.randn(n, self.x_dim)\n",
    "            if t==0: noise= torch.zeros(n, self.x_dim)\n",
    "\n",
    "            sigma = torch.sqrt(self.beta[t]*(1-self.alpha[t-1])/(1-self.alpha[t]))\n",
    "\n",
    "            noise_pred = self.model(x_sample.to(self.device),\n",
    "                                    c_sample.to(self.device),\n",
    "                                    torch.tensor([[t]]).float().to(self.device)).detach().cpu()\n",
    "\n",
    "            # import ipdb;ipdb.set_trace()\n",
    "            x_sample = (x_sample - self.beta[t]*noise_pred/torch.sqrt(1-self.alpha[t])) / torch.sqrt(1-self.beta[t]) + sigma * noise\n",
    "\n",
    "\n",
    "        return x_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'episode_2.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# extraction: timestamp, action, position, velocity\n",
    "x = data['action'].values[:,None]\n",
    "c = data[['position', 'velocity']].values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.8605612295645254\n",
      "epoch: 1, loss: 2.8899129231770835\n",
      "epoch: 2, loss: 2.536378648546007\n",
      "epoch: 3, loss: 0.961448245578342\n",
      "epoch: 4, loss: 0.8454933166503906\n",
      "epoch: 5, loss: 1.3788070678710938\n",
      "epoch: 6, loss: 1.077204668963397\n",
      "epoch: 7, loss: 0.9678839224356192\n",
      "epoch: 8, loss: 0.8232475563331887\n",
      "epoch: 9, loss: 0.5978144892939815\n",
      "epoch: 10, loss: 0.9958890985559534\n",
      "epoch: 11, loss: 0.6891616538718894\n",
      "epoch: 12, loss: 0.6332956243444372\n",
      "epoch: 13, loss: 0.5886618296305338\n",
      "epoch: 14, loss: 0.5597443050808377\n",
      "epoch: 15, loss: 0.8995347199616609\n",
      "epoch: 16, loss: 0.4540381254973235\n",
      "epoch: 17, loss: 0.39634407891167533\n",
      "epoch: 18, loss: 0.39342209144874857\n",
      "epoch: 19, loss: 1.1020021791811343\n",
      "epoch: 20, loss: 0.5410966519956235\n",
      "epoch: 21, loss: 0.4470794112594039\n",
      "epoch: 22, loss: 0.27570445449263964\n",
      "epoch: 23, loss: 0.9504417843288846\n",
      "epoch: 24, loss: 0.5017077128092448\n",
      "epoch: 25, loss: 0.41103193495008683\n",
      "epoch: 26, loss: 0.3044974009195964\n",
      "epoch: 27, loss: 0.14925147868968822\n",
      "epoch: 28, loss: 0.22098281648423937\n",
      "epoch: 29, loss: 0.8111825165925203\n",
      "epoch: 30, loss: 0.32808081309000653\n",
      "epoch: 31, loss: 0.4863915973239475\n",
      "epoch: 32, loss: 0.39726557555022063\n",
      "epoch: 33, loss: 0.3309268244990596\n",
      "epoch: 34, loss: 0.812283127396195\n",
      "epoch: 35, loss: 0.3725648809362341\n",
      "epoch: 36, loss: 0.2541347786232277\n",
      "epoch: 37, loss: 0.25080202243946215\n",
      "epoch: 38, loss: 0.32362450493706596\n",
      "epoch: 39, loss: 0.5120976412737811\n",
      "epoch: 40, loss: 0.5412209122269241\n",
      "epoch: 41, loss: 0.5263264620745624\n",
      "epoch: 42, loss: 0.15686063413266782\n",
      "epoch: 43, loss: 0.40747935683638964\n",
      "epoch: 44, loss: 0.2498589798256203\n",
      "epoch: 45, loss: 0.24669892699630172\n",
      "epoch: 46, loss: 0.38366342473913123\n",
      "epoch: 47, loss: 0.14940164707325124\n",
      "epoch: 48, loss: 0.42874601152208114\n",
      "epoch: 49, loss: 0.38794199625651044\n",
      "epoch: 50, loss: 0.28876686096191406\n",
      "epoch: 51, loss: 0.8044960587112991\n",
      "epoch: 52, loss: 0.3475627545957212\n",
      "epoch: 53, loss: 0.2928392268993236\n",
      "epoch: 54, loss: 0.16863441467285156\n",
      "epoch: 55, loss: 0.27702096656516745\n",
      "epoch: 56, loss: 0.27987024519178605\n",
      "epoch: 57, loss: 0.3596072726779514\n",
      "epoch: 58, loss: 0.4106502886171694\n",
      "epoch: 59, loss: 0.31892391487404154\n",
      "epoch: 60, loss: 0.447002198961046\n",
      "epoch: 61, loss: 0.19926311351634837\n",
      "epoch: 62, loss: 0.19458979147451896\n",
      "epoch: 63, loss: 0.17006399013378\n",
      "epoch: 64, loss: 0.4087583400585033\n",
      "epoch: 65, loss: 0.738682711565936\n",
      "epoch: 66, loss: 0.3684689557110822\n",
      "epoch: 67, loss: 0.21905669459590205\n",
      "epoch: 68, loss: 0.1519769032796224\n",
      "epoch: 69, loss: 0.17320094285187898\n",
      "epoch: 70, loss: 0.49217693893997755\n",
      "epoch: 71, loss: 0.37951942726417826\n",
      "epoch: 72, loss: 0.6805544959174262\n",
      "epoch: 73, loss: 0.30999155397768374\n",
      "epoch: 74, loss: 0.41282289999502675\n",
      "epoch: 75, loss: 0.583888018572772\n",
      "epoch: 76, loss: 0.38371139102511936\n",
      "epoch: 77, loss: 0.7498287624782987\n",
      "epoch: 78, loss: 0.5638203797517\n",
      "epoch: 79, loss: 0.34885568971987124\n",
      "epoch: 80, loss: 0.22545164602774162\n",
      "epoch: 81, loss: 0.28812706912005387\n",
      "epoch: 82, loss: 0.23674239052666557\n",
      "epoch: 83, loss: 0.33485469111689814\n",
      "epoch: 84, loss: 0.5310562981499566\n",
      "epoch: 85, loss: 0.5969561824092159\n",
      "epoch: 86, loss: 0.3706775947853371\n",
      "epoch: 87, loss: 0.42918371271204064\n",
      "epoch: 88, loss: 0.37489198755334924\n",
      "epoch: 89, loss: 0.3159994196008753\n",
      "epoch: 90, loss: 0.47723466378671153\n",
      "epoch: 91, loss: 0.4422470375343605\n",
      "epoch: 92, loss: 0.5427320974844473\n",
      "epoch: 93, loss: 0.22541738439489295\n",
      "epoch: 94, loss: 0.39691522386338973\n",
      "epoch: 95, loss: 0.5914575788709853\n",
      "epoch: 96, loss: 0.3278984140466761\n",
      "epoch: 97, loss: 0.49260203043619794\n",
      "epoch: 98, loss: 0.15005835780390986\n",
      "epoch: 99, loss: 0.28148278483638056\n"
     ]
    }
   ],
   "source": [
    "beta = np.exp(np.linspace(np.log(0.001), np.log(0.9), 300))\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "ddpm = ConditionalDenoisingDiffusionProbabilisticModel(\n",
    "                torch.tensor(x).float(),\n",
    "                torch.tensor(c).float(),\n",
    "                torch.tensor(beta).float(), device, batch_size=32)\n",
    "\n",
    "ddpm.learning(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_execute(env, ddpm, device, n_steps, output_file = 'execution_log.csv'):\n",
    "    # observation from gym evironment\n",
    "    observation, _ = env.reset()\n",
    "\n",
    "    # initialize a dataframe to log the data\n",
    "    log_data =[]\n",
    "\n",
    "    for step in range(n_steps):\n",
    "        position = observation[0]\n",
    "        velocity = observation[1]\n",
    "\n",
    "        c_tensor = torch.tensor([[position, velocity]], dtype = torch.float32).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            action_tensor = ddpm.sampling(c_tensor)\n",
    "        \n",
    "        action = action_tensor.cpu().numpy().flatten()\n",
    "\n",
    "        # execute action in the environment\n",
    "        observation, reward, done,_,_ = env.step(action)\n",
    "\n",
    "        env.render()\n",
    "\n",
    "        timestamp = time.time()\n",
    "\n",
    "        # log data into csv file\n",
    "        log_data.append({'timestamp':timestamp, 'action':action[0], 'position':position, 'velocity': velocity})\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "        time.sleep(0.1)\n",
    "    \n",
    "    log_df = pd.DataFrame(log_data)\n",
    "    log_df.to_csv(output_file , index = False)      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    env = gym.make('MountainCarContinuous-v0', render_mode=\"human\")\n",
    "    ddpm = ConditionalDenoisingDiffusionProbabilisticModel(torch.tensor(x).float(),\n",
    "                torch.tensor(c).float(),\n",
    "                torch.tensor(beta).float(), device, batch_size=32)\n",
    "    predict_and_execute(env,ddpm, device, n_steps=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dif_aug_cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
