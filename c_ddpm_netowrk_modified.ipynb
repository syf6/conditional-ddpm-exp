{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import gymnasium as gym\n",
    "import csv\n",
    "import time\n",
    "from gym.wrappers import RecordVideo\n",
    "\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalDiffusionNet(nn.Module):\n",
    "    def __init__(self,data_dim,cond_dim):\n",
    "        super(ConditionalDiffusionNet,self).__init__()\n",
    "        n_unit = 256\n",
    "\n",
    "        self.l1 = nn.Linear(data_dim, n_unit)\n",
    "        self.l2 = nn.Linear(n_unit, n_unit)\n",
    "\n",
    "        self.l1_beta = nn.Linear(1, n_unit)\n",
    "        self.l2_beta = nn.Linear(n_unit, n_unit)\n",
    "\n",
    "        self.l1_cond = nn.Linear(cond_dim, n_unit)\n",
    "        self.l2_cond = nn.Linear(n_unit, n_unit)\n",
    "\n",
    "        self.l3 = nn.Linear(n_unit,n_unit)\n",
    "        # self.l4 = nn.Linear(n_unit,data_dim)\n",
    "        self.l4 = nn.Linear(n_unit, 1)\n",
    "    \n",
    "    def forward(self,x,c,t):\n",
    "        xx = self.l1(x)\n",
    "        xx = F.relu(xx)\n",
    "        xx = self.l2(xx)\n",
    "        xx = F.relu(xx)\n",
    "\n",
    "        cc = self.l1_cond(c)\n",
    "        cc = F.relu(cc)\n",
    "        cc = self.l2_cond(cc)\n",
    "        cc = F.relu(cc)\n",
    "\n",
    "        bb = self.l1_beta(t)\n",
    "        bb = F.relu(bb)\n",
    "        bb = self.l2_beta(bb)\n",
    "        bb = F.relu(bb)\n",
    "\n",
    "        xx = self.l3(xx+bb+cc)\n",
    "        xx = F.relu(xx)\n",
    "        xx = self.l4(xx)\n",
    "\n",
    "        return xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalDenoisingDiffusionProbabilisticModel():\n",
    "    def __init__(self, X, cond, beta, device, batch_size=32):\n",
    "        self.device = device\n",
    "\n",
    "        self.X = X\n",
    "        self.x_dim = self.X.shape[1]\n",
    "        self.C = cond\n",
    "        self.c_dim = self.C.shape[1]\n",
    "        self.beta = beta\n",
    "        self.n_beta = self.beta.shape[0]\n",
    "\n",
    "        alpha = 1 - self.beta\n",
    "        self.alpha = torch.tensor([[torch.prod(alpha[:i+1])] for i in range(self.n_beta)]).float()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.model = ConditionalDiffusionNet(self.X.shape[1], self.C.shape[1]).to(self.device)\n",
    "\n",
    "        train_dataset = torch.utils.data.TensorDataset(self.X, self.C)\n",
    "        self.train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=1e-5)\n",
    "\n",
    "\n",
    "\n",
    "    def learning(self, n_epoch=10):\n",
    "        self.model.train()\n",
    "\n",
    "        for e in range(n_epoch):\n",
    "            for (x_batch, c_batch) in self.train_loader:\n",
    "                loss_hist = []\n",
    "\n",
    "                x_batch = x_batch\n",
    "                c_batch = c_batch\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                t = torch.randint(low=0, high=self.n_beta, size=(x_batch.shape[0],))\n",
    "                noise = torch.randn(x_batch.shape[0], self.x_dim)\n",
    "\n",
    "\n",
    "                x_t = torch.sqrt(self.alpha[t]) * x_batch + torch.sqrt(1-self.alpha[t]) * noise\n",
    "\n",
    "                noise_pred = self.model(x_t.to(self.device),\n",
    "                                        c_batch.to(self.device),\n",
    "                                        t[:,None].float().to(self.device))\n",
    "\n",
    "\n",
    "                # import ipdb; ipdb.set_trace()\n",
    "                # loss = ((noise_pred - noise.to(device))**2).sum()\n",
    "                loss = ((noise_pred - noise.to(self.device))**2).mean()  # use mse loss\n",
    "\n",
    "                # loss_hist.append(loss.detach().cpu().numpy()/x_batch.shape[0])\n",
    "                loss_hist.append(loss.detach().cpu().numpy())  #record current loss value\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "                self.optimizer.step()\n",
    "\n",
    "            print('epoch: {}, loss: {}'.format(e, np.array(loss_hist).mean()))\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "\n",
    "\n",
    "    def sampling(self, c, n=100):\n",
    "        # x_sample = torch.randn(n, self.x_dim)\n",
    "        x_sample = torch.randn(n, 1)  # n is sampling time，1 is output action dimension\n",
    "\n",
    "        c_sample = c.repeat(n, 1)\n",
    "\n",
    "        for t in range(self.n_beta)[::-1]:\n",
    "            noise = torch.randn(n, self.x_dim)\n",
    "            if t==0: noise= torch.zeros(n, self.x_dim)\n",
    "\n",
    "            sigma = torch.sqrt(self.beta[t]*(1-self.alpha[t-1])/(1-self.alpha[t]))\n",
    "\n",
    "            noise_pred = self.model(x_sample.to(self.device),\n",
    "                                    c_sample.to(self.device),\n",
    "                                    torch.tensor([[t]]).float().to(self.device)).detach().cpu()\n",
    "\n",
    "            # import ipdb;ipdb.set_trace()\n",
    "            x_sample = (x_sample - self.beta[t]*noise_pred/torch.sqrt(1-self.alpha[t])) / torch.sqrt(1-self.beta[t]) + sigma * noise\n",
    "        \n",
    "        x_sample = torch.clamp(x_sample, -1, 1)  # clamp action value to [-1, 1]\n",
    "\n",
    "        return x_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'combined_episodes_big_small_random.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# extraction: timestamp, action, position, velocity\n",
    "x = data['action'].values[:,None]\n",
    "c = data[['position', 'velocity']].values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.916404128074646\n",
      "epoch: 1, loss: 0.5071741938591003\n",
      "epoch: 2, loss: 0.12865185737609863\n",
      "epoch: 3, loss: 0.2108181118965149\n",
      "epoch: 4, loss: 0.0329340398311615\n",
      "epoch: 5, loss: 0.19527988135814667\n",
      "epoch: 6, loss: 0.15800178050994873\n",
      "epoch: 7, loss: 0.2860020399093628\n",
      "epoch: 8, loss: 0.06446629017591476\n",
      "epoch: 9, loss: 0.04216674715280533\n",
      "epoch: 10, loss: 0.590259313583374\n",
      "epoch: 11, loss: 0.46445807814598083\n",
      "epoch: 12, loss: 0.05013973265886307\n",
      "epoch: 13, loss: 0.4139255881309509\n",
      "epoch: 14, loss: 0.11840444803237915\n",
      "epoch: 15, loss: 0.4390581250190735\n",
      "epoch: 16, loss: 0.11076533049345016\n",
      "epoch: 17, loss: 0.7463089823722839\n",
      "epoch: 18, loss: 0.2868988811969757\n",
      "epoch: 19, loss: 0.4685055613517761\n",
      "epoch: 20, loss: 1.4790648221969604\n",
      "epoch: 21, loss: 0.11345934867858887\n",
      "epoch: 22, loss: 0.22855117917060852\n",
      "epoch: 23, loss: 0.03775947168469429\n",
      "epoch: 24, loss: 0.11225132644176483\n",
      "epoch: 25, loss: 0.9348472356796265\n",
      "epoch: 26, loss: 0.1656842678785324\n",
      "epoch: 27, loss: 0.33640211820602417\n",
      "epoch: 28, loss: 0.12211467325687408\n",
      "epoch: 29, loss: 0.09558101743459702\n",
      "epoch: 30, loss: 0.25464046001434326\n",
      "epoch: 31, loss: 0.047214433550834656\n",
      "epoch: 32, loss: 0.04326842352747917\n",
      "epoch: 33, loss: 0.19158822298049927\n",
      "epoch: 34, loss: 0.10644444078207016\n",
      "epoch: 35, loss: 0.561926007270813\n",
      "epoch: 36, loss: 0.05903905630111694\n",
      "epoch: 37, loss: 0.605929970741272\n",
      "epoch: 38, loss: 0.16054567694664001\n",
      "epoch: 39, loss: 0.0482126921415329\n",
      "epoch: 40, loss: 0.5520943403244019\n",
      "epoch: 41, loss: 0.16428609192371368\n",
      "epoch: 42, loss: 0.26455843448638916\n",
      "epoch: 43, loss: 0.32478004693984985\n",
      "epoch: 44, loss: 0.10877461731433868\n",
      "epoch: 45, loss: 0.36247166991233826\n",
      "epoch: 46, loss: 0.24507367610931396\n",
      "epoch: 47, loss: 0.1091134175658226\n",
      "epoch: 48, loss: 0.28586429357528687\n",
      "epoch: 49, loss: 0.90521240234375\n",
      "epoch: 50, loss: 0.4841326177120209\n",
      "epoch: 51, loss: 0.01879662089049816\n",
      "epoch: 52, loss: 0.5880908966064453\n",
      "epoch: 53, loss: 0.13559719920158386\n",
      "epoch: 54, loss: 0.2226627916097641\n",
      "epoch: 55, loss: 0.13454648852348328\n",
      "epoch: 56, loss: 0.03538725525140762\n",
      "epoch: 57, loss: 0.60713791847229\n",
      "epoch: 58, loss: 1.120729923248291\n",
      "epoch: 59, loss: 0.23290321230888367\n",
      "epoch: 60, loss: 0.06372376531362534\n",
      "epoch: 61, loss: 0.0816672071814537\n",
      "epoch: 62, loss: 0.08889561146497726\n",
      "epoch: 63, loss: 0.6108996868133545\n",
      "epoch: 64, loss: 0.04930127412080765\n",
      "epoch: 65, loss: 0.11315301060676575\n",
      "epoch: 66, loss: 0.06733334064483643\n",
      "epoch: 67, loss: 0.011069826781749725\n",
      "epoch: 68, loss: 0.18152639269828796\n",
      "epoch: 69, loss: 0.06097887083888054\n",
      "epoch: 70, loss: 0.3454504907131195\n",
      "epoch: 71, loss: 0.07399208843708038\n",
      "epoch: 72, loss: 0.10085945576429367\n",
      "epoch: 73, loss: 0.015300745144486427\n",
      "epoch: 74, loss: 0.43076300621032715\n",
      "epoch: 75, loss: 0.15430215001106262\n",
      "epoch: 76, loss: 0.6863982677459717\n",
      "epoch: 77, loss: 0.39967069029808044\n",
      "epoch: 78, loss: 0.9864660501480103\n",
      "epoch: 79, loss: 0.2997969388961792\n",
      "epoch: 80, loss: 0.3688907027244568\n",
      "epoch: 81, loss: 0.30421414971351624\n",
      "epoch: 82, loss: 0.045280568301677704\n",
      "epoch: 83, loss: 0.06708282977342606\n",
      "epoch: 84, loss: 0.4212888181209564\n",
      "epoch: 85, loss: 0.121303491294384\n",
      "epoch: 86, loss: 0.048804931342601776\n",
      "epoch: 87, loss: 0.18067674338817596\n",
      "epoch: 88, loss: 0.4115295112133026\n",
      "epoch: 89, loss: 0.4228702485561371\n",
      "epoch: 90, loss: 0.06682807207107544\n",
      "epoch: 91, loss: 0.4374729096889496\n",
      "epoch: 92, loss: 0.22272776067256927\n",
      "epoch: 93, loss: 0.2450728714466095\n",
      "epoch: 94, loss: 0.16932299733161926\n",
      "epoch: 95, loss: 0.02598075568675995\n",
      "epoch: 96, loss: 0.03563139587640762\n",
      "epoch: 97, loss: 0.6600251793861389\n",
      "epoch: 98, loss: 0.024656955152750015\n",
      "epoch: 99, loss: 0.6913911700248718\n"
     ]
    }
   ],
   "source": [
    "beta = np.exp(np.linspace(np.log(0.001), np.log(0.9), 300))\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "ddpm = ConditionalDenoisingDiffusionProbabilisticModel(\n",
    "                torch.tensor(x).float(),\n",
    "                torch.tensor(c).float(),\n",
    "                torch.tensor(beta).float(), device, batch_size=32)\n",
    "\n",
    "ddpm.learning(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_execute(env, ddpm, device, n_steps, output_file = 'exe_log_network_modified.csv'):\n",
    "    # observation from gym evironment\n",
    "    observation, _ = env.reset()\n",
    "\n",
    "    # initialize a dataframe to log the data\n",
    "    log_data =[]\n",
    "\n",
    "    for step in range(n_steps):\n",
    "        position = observation[0]\n",
    "        velocity = observation[1]\n",
    "\n",
    "        c_tensor = torch.tensor([[position, velocity]], dtype = torch.float32).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            action_tensor = ddpm.sampling(c_tensor)\n",
    "        \n",
    "        action = action_tensor.cpu().numpy().flatten()\n",
    "        action = np.clip(action, -1, 1) # added\n",
    "        # execute action in the environment\n",
    "        observation, reward, done,_,_ = env.step(action)\n",
    "\n",
    "        env.render()\n",
    "\n",
    "        timestamp = time.time()\n",
    "\n",
    "        # log data into csv file\n",
    "        log_data.append({'timestamp':timestamp, 'action':action[0], 'position':position, 'velocity': velocity})\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "        time.sleep(0.1)\n",
    "    \n",
    "    log_df = pd.DataFrame(log_data)\n",
    "    log_df.to_csv(output_file , index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    env = gym.make('MountainCarContinuous-v0', render_mode=\"human\")\n",
    "    ddpm = ConditionalDenoisingDiffusionProbabilisticModel(torch.tensor(x).float(),\n",
    "                torch.tensor(c).float(),\n",
    "                torch.tensor(beta).float(), device, batch_size=32)\n",
    "    predict_and_execute(env,ddpm, device, n_steps=3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a list of velocity and position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_execute(env, ddpm, device, n_steps, output_file = 'exe_log_network_modified.csv'):\n",
    "    # observation from gym evironment\n",
    "    observation, _ = env.reset()\n",
    "\n",
    "    # initialize a dataframe to log the data\n",
    "    log_data =[]\n",
    "\n",
    "    position_list = []\n",
    "    velocity_list = []\n",
    "\n",
    "    for step in range(n_steps):\n",
    "        position = observation[0]\n",
    "        velocity = observation[1]\n",
    "        \n",
    "        position_list.append(position)\n",
    "        velocity_list.append(velocity)\n",
    "\n",
    "        c_tensor = torch.tensor([[position_list, velocity_list]], dtype = torch.float32).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            action_tensor = ddpm.sampling(c_tensor)\n",
    "        \n",
    "        action = action_tensor.cpu().numpy().flatten()\n",
    "        action = np.clip(action, -1, 1) # added\n",
    "        # execute action in the environment\n",
    "        observation, reward, done,_,_ = env.step(action)\n",
    "\n",
    "        env.render()\n",
    "\n",
    "        timestamp = time.time()\n",
    "\n",
    "        # log data into csv file\n",
    "        log_data.append({'timestamp':timestamp, 'action':action[0], 'position':position, 'velocity': velocity})\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "        time.sleep(0.1)\n",
    "    \n",
    "    log_df = pd.DataFrame(log_data)\n",
    "    log_df.to_csv(output_file , index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m env \u001b[38;5;241m=\u001b[39m gym\u001b[38;5;241m.\u001b[39mmake(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMountainCarContinuous-v0\u001b[39m\u001b[38;5;124m'\u001b[39m, render_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m ddpm \u001b[38;5;241m=\u001b[39m ConditionalDenoisingDiffusionProbabilisticModel(torch\u001b[38;5;241m.\u001b[39mtensor(x)\u001b[38;5;241m.\u001b[39mfloat(),\n\u001b[0;32m      4\u001b[0m             torch\u001b[38;5;241m.\u001b[39mtensor(c)\u001b[38;5;241m.\u001b[39mfloat(),\n\u001b[0;32m      5\u001b[0m             torch\u001b[38;5;241m.\u001b[39mtensor(beta)\u001b[38;5;241m.\u001b[39mfloat(), device, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mpredict_and_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43mddpm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 21\u001b[0m, in \u001b[0;36mpredict_and_execute\u001b[1;34m(env, ddpm, device, n_steps, output_file)\u001b[0m\n\u001b[0;32m     18\u001b[0m c_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[position_list, velocity_list]], dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 21\u001b[0m     action_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mddpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m action \u001b[38;5;241m=\u001b[39m action_tensor\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     24\u001b[0m action \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(action, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# added\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 70\u001b[0m, in \u001b[0;36mConditionalDenoisingDiffusionProbabilisticModel.sampling\u001b[1;34m(self, c, n)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msampling\u001b[39m(\u001b[38;5;28mself\u001b[39m, c, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m):\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# x_sample = torch.randn(n, self.x_dim)\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     x_sample \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(n, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# n is sampling time，1 is output action dimension\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     c_sample \u001b[38;5;241m=\u001b[39m \u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_beta)[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m     73\u001b[0m         noise \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(n, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_dim)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    env = gym.make('MountainCarContinuous-v0', render_mode=\"human\")\n",
    "    ddpm = ConditionalDenoisingDiffusionProbabilisticModel(torch.tensor(x).float(),\n",
    "                torch.tensor(c).float(),\n",
    "                torch.tensor(beta).float(), device, batch_size=32)\n",
    "    predict_and_execute(env,ddpm, device, n_steps=3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe we need to modify the sampling method ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the Individual Action L2 Error\n",
    "\n",
    "1) Without modifying the sampling method, only the network (not take action[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss is 1.0\n",
      "1 loss is 1.0\n",
      "2 loss is 1.0\n",
      "3 loss is 1.0\n",
      "4 loss is 1.0\n",
      "5 loss is 1.0\n",
      "6 loss is 1.0\n",
      "7 loss is 1.0\n",
      "8 loss is 1.0\n",
      "9 loss is 1.0\n",
      "10 loss is 1.0\n",
      "11 loss is 1.0\n",
      "12 loss is 1.0\n",
      "13 loss is 1.0\n",
      "14 loss is 1.0\n",
      "15 loss is 1.0\n",
      "16 loss is 1.0\n",
      "17 loss is 1.07965087890625\n",
      "18 loss is 1.5625\n",
      "19 loss is 2.392822265625\n",
      "20 loss is 3.3994140625\n",
      "21 loss is 4.0\n",
      "22 loss is 4.0\n",
      "23 loss is 4.0\n",
      "24 loss is 4.0\n",
      "25 loss is 4.0\n",
      "26 loss is 4.0\n",
      "27 loss is 4.0\n",
      "28 loss is 4.0\n",
      "29 loss is 4.0\n",
      "30 loss is 4.0\n",
      "31 loss is 4.0\n",
      "32 loss is 4.0\n",
      "33 loss is 4.0\n",
      "34 loss is 4.0\n",
      "35 loss is 4.0\n",
      "36 loss is 4.0\n",
      "37 loss is 4.0\n",
      "38 loss is 4.0\n",
      "39 loss is 4.0\n",
      "40 loss is 4.0\n",
      "41 loss is 4.0\n",
      "42 loss is 4.0\n",
      "43 loss is 4.0\n",
      "44 loss is 4.0\n",
      "45 loss is 4.0\n",
      "46 loss is 4.0\n",
      "47 loss is 4.0\n",
      "48 loss is 4.0\n",
      "49 loss is 4.0\n",
      "50 loss is 2.92730712890625\n",
      "51 loss is 1.523681640625\n",
      "52 loss is 1.0\n",
      "53 loss is 1.0\n",
      "54 loss is 1.0\n",
      "55 loss is 1.0\n",
      "56 loss is 1.0\n",
      "57 loss is 1.0\n",
      "58 loss is 1.0\n",
      "59 loss is 1.0\n",
      "60 loss is 1.0\n",
      "61 loss is 0.8622206086292863\n",
      "62 loss is 0.5101729417219758\n",
      "63 loss is 0.12194947246462107\n",
      "64 loss is 0.009077493101358414\n",
      "65 loss is 6.344262510538101e-05\n",
      "66 loss is 9.313225746154785e-10\n",
      "67 loss is 9.313225746154785e-10\n",
      "68 loss is 9.313225746154785e-10\n",
      "69 loss is 9.313225746154785e-10\n",
      "70 loss is 9.313225746154785e-10\n",
      "71 loss is 9.313225746154785e-10\n",
      "72 loss is 9.313225746154785e-10\n",
      "73 loss is 9.313225746154785e-10\n",
      "74 loss is 9.313225746154785e-10\n",
      "75 loss is 9.313225746154785e-10\n",
      "76 loss is 9.313225746154785e-10\n",
      "77 loss is 9.313225746154785e-10\n",
      "78 loss is 9.313225746154785e-10\n",
      "79 loss is 9.313225746154785e-10\n",
      "80 loss is 9.313225746154785e-10\n",
      "81 loss is 9.313225746154785e-10\n",
      "82 loss is 9.313225746154785e-10\n",
      "83 loss is 9.313225746154785e-10\n",
      "84 loss is 9.313225746154785e-10\n",
      "85 loss is 9.313225746154785e-10\n",
      "86 loss is 9.313225746154785e-10\n",
      "87 loss is 9.313225746154785e-10\n",
      "88 loss is 9.313225746154785e-10\n",
      "89 loss is 9.313225746154785e-10\n",
      "90 loss is 9.313225746154785e-10\n",
      "91 loss is 9.313225746154785e-10\n",
      "92 loss is 9.313225746154785e-10\n",
      "93 loss is 9.313225746154785e-10\n",
      "L2 Loss: 1.663711276182786\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def calculate_l2_loss_from_csv(csv_file, ddpm, device):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    true_actions = df['action'].values[:, None]  # (n_steps, 1)\n",
    "\n",
    "    total_loss = 0.0\n",
    "    n_steps = len(df)\n",
    "\n",
    "    for i in range(n_steps):\n",
    "        c = df[['position', 'velocity']].iloc[i].values[None, :]  # (1, 2)\n",
    "\n",
    "        c_tensor = torch.tensor(c, dtype=torch.float32).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predicted_action_tensor = ddpm.sampling(c_tensor)\n",
    "\n",
    "        # -> numpy\n",
    "        predicted_action = predicted_action_tensor.cpu().numpy().flatten()  # (action_dim,)\n",
    "\n",
    "        loss = (predicted_action - true_actions[i]) ** 2  # (1,)\n",
    "\n",
    "        print(f\"{i} loss is {loss[0]}\")  # 打印当前损失\n",
    "\n",
    "        total_loss += loss[0]\n",
    "\n",
    "    l2_loss = total_loss / n_steps\n",
    "    print(f'L2 Loss: {l2_loss}')\n",
    "    return l2_loss\n",
    "\n",
    "csv_file = 'episode_3.csv'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "l2_loss = calculate_l2_loss_from_csv(csv_file, ddpm, device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dif_aug_cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
