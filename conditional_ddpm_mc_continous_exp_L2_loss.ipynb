{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import gymnasium as gym\n",
    "import csv\n",
    "import time\n",
    "from gym.wrappers import RecordVideo\n",
    "\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalDiffusionNet(nn.Module):\n",
    "    def __init__(self,data_dim,cond_dim):\n",
    "        super(ConditionalDiffusionNet,self).__init__()\n",
    "        n_unit = 256\n",
    "\n",
    "        self.l1 = nn.Linear(data_dim, n_unit)\n",
    "        self.l2 = nn.Linear(n_unit, n_unit)\n",
    "\n",
    "        self.l1_beta = nn.Linear(1, n_unit)\n",
    "        self.l2_beta = nn.Linear(n_unit, n_unit)\n",
    "\n",
    "        self.l1_cond = nn.Linear(cond_dim, n_unit)\n",
    "        self.l2_cond = nn.Linear(n_unit, n_unit)\n",
    "\n",
    "        self.l3 = nn.Linear(n_unit,n_unit)\n",
    "        self.l4 = nn.Linear(n_unit,data_dim)\n",
    "    \n",
    "    def forward(self,x,c,t):\n",
    "        xx = self.l1(x)\n",
    "        xx = F.relu(xx)\n",
    "        xx = self.l2(xx)\n",
    "        xx = F.relu(xx)\n",
    "\n",
    "        cc = self.l1_cond(c)\n",
    "        cc = F.relu(cc)\n",
    "        cc = self.l2_cond(cc)\n",
    "        cc = F.relu(cc)\n",
    "\n",
    "        bb = self.l1_beta(t)\n",
    "        bb = F.relu(bb)\n",
    "        bb = self.l2_beta(bb)\n",
    "        bb = F.relu(bb)\n",
    "\n",
    "        xx = self.l3(xx+bb+cc)\n",
    "        xx = F.relu(xx)\n",
    "        xx = self.l4(xx)\n",
    "\n",
    "        return xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalDenoisingDiffusionProbabilisticModel():\n",
    "    def __init__(self, X, cond, beta, device, batch_size=32):\n",
    "        self.device = device\n",
    "\n",
    "        self.X = X\n",
    "        self.x_dim = self.X.shape[1]\n",
    "        self.C = cond\n",
    "        self.c_dim = self.C.shape[1]\n",
    "        self.beta = beta\n",
    "        self.n_beta = self.beta.shape[0]\n",
    "\n",
    "        alpha = 1 - self.beta\n",
    "        self.alpha = torch.tensor([[torch.prod(alpha[:i+1])] for i in range(self.n_beta)]).float()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.model = ConditionalDiffusionNet(self.X.shape[1], self.C.shape[1]).to(self.device)\n",
    "\n",
    "        train_dataset = torch.utils.data.TensorDataset(self.X, self.C)\n",
    "        self.train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=1e-5)\n",
    "\n",
    "\n",
    "\n",
    "    def learning(self, n_epoch=10):\n",
    "        self.model.train()\n",
    "\n",
    "        for e in range(n_epoch):\n",
    "            for (x_batch, c_batch) in self.train_loader:\n",
    "                loss_hist = []\n",
    "\n",
    "                x_batch = x_batch\n",
    "                c_batch = c_batch\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                t = torch.randint(low=0, high=self.n_beta, size=(x_batch.shape[0],))\n",
    "                noise = torch.randn(x_batch.shape[0], self.x_dim)\n",
    "\n",
    "\n",
    "                x_t = torch.sqrt(self.alpha[t]) * x_batch + torch.sqrt(1-self.alpha[t]) * noise\n",
    "\n",
    "                noise_pred = self.model(x_t.to(self.device),\n",
    "                                        c_batch.to(self.device),\n",
    "                                        t[:,None].float().to(self.device))\n",
    "\n",
    "\n",
    "                # import ipdb; ipdb.set_trace()\n",
    "                loss = ((noise_pred - noise.to(device))**2).sum()\n",
    "                loss_hist.append(loss.detach().cpu().numpy()/x_batch.shape[0])\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "                self.optimizer.step()\n",
    "\n",
    "            print('epoch: {}, loss: {}'.format(e, np.array(loss_hist).mean()))\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "\n",
    "\n",
    "    def sampling(self, c, n=100):\n",
    "        x_sample = torch.randn(n, self.x_dim)\n",
    "        c_sample = c.repeat(n, 1)\n",
    "\n",
    "        for t in range(self.n_beta)[::-1]:\n",
    "            noise = torch.randn(n, self.x_dim)\n",
    "            if t==0: noise= torch.zeros(n, self.x_dim)\n",
    "\n",
    "            sigma = torch.sqrt(self.beta[t]*(1-self.alpha[t-1])/(1-self.alpha[t]))\n",
    "\n",
    "            noise_pred = self.model(x_sample.to(self.device),\n",
    "                                    c_sample.to(self.device),\n",
    "                                    torch.tensor([[t]]).float().to(self.device)).detach().cpu()\n",
    "\n",
    "            # import ipdb;ipdb.set_trace()\n",
    "            x_sample = (x_sample - self.beta[t]*noise_pred/torch.sqrt(1-self.alpha[t])) / torch.sqrt(1-self.beta[t]) + sigma * noise\n",
    "\n",
    "\n",
    "        return x_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'combined_big_random_expert_trajectory.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# extraction: timestamp, action, position, velocity\n",
    "x = data['action'].values[:,None]\n",
    "c = data[['position', 'velocity']].values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 1.5163229703903198\n",
      "epoch: 1, loss: 0.7746973037719727\n",
      "epoch: 2, loss: 0.7700782418251038\n",
      "epoch: 3, loss: 0.26188766956329346\n",
      "epoch: 4, loss: 0.20814526081085205\n",
      "epoch: 5, loss: 0.4005023241043091\n",
      "epoch: 6, loss: 0.14230789244174957\n",
      "epoch: 7, loss: 0.288875937461853\n",
      "epoch: 8, loss: 0.2921074628829956\n",
      "epoch: 9, loss: 0.2391005903482437\n",
      "epoch: 10, loss: 0.3266739845275879\n",
      "epoch: 11, loss: 0.13524818420410156\n",
      "epoch: 12, loss: 0.22946017980575562\n",
      "epoch: 13, loss: 0.27820906043052673\n",
      "epoch: 14, loss: 0.3553852140903473\n",
      "epoch: 15, loss: 0.17442640662193298\n",
      "epoch: 16, loss: 0.22408337891101837\n",
      "epoch: 17, loss: 0.19716514647006989\n",
      "epoch: 18, loss: 0.260698139667511\n",
      "epoch: 19, loss: 0.2330121397972107\n",
      "epoch: 20, loss: 0.19997426867485046\n",
      "epoch: 21, loss: 0.2207825779914856\n",
      "epoch: 22, loss: 0.11276985704898834\n",
      "epoch: 23, loss: 0.47054165601730347\n",
      "epoch: 24, loss: 0.2126162350177765\n",
      "epoch: 25, loss: 0.24453948438167572\n",
      "epoch: 26, loss: 0.3139303922653198\n",
      "epoch: 27, loss: 0.276422917842865\n",
      "epoch: 28, loss: 0.15735477209091187\n",
      "epoch: 29, loss: 0.29165059328079224\n",
      "epoch: 30, loss: 0.29964110255241394\n",
      "epoch: 31, loss: 0.15806570649147034\n",
      "epoch: 32, loss: 0.3021222651004791\n",
      "epoch: 33, loss: 0.3762570321559906\n",
      "epoch: 34, loss: 0.2721659541130066\n",
      "epoch: 35, loss: 0.2997905910015106\n",
      "epoch: 36, loss: 0.5198990702629089\n",
      "epoch: 37, loss: 0.22416582703590393\n",
      "epoch: 38, loss: 0.4214787483215332\n",
      "epoch: 39, loss: 0.1382438838481903\n",
      "epoch: 40, loss: 0.16763344407081604\n",
      "epoch: 41, loss: 0.5093395709991455\n",
      "epoch: 42, loss: 0.16338029503822327\n",
      "epoch: 43, loss: 0.36599040031433105\n",
      "epoch: 44, loss: 0.26494306325912476\n",
      "epoch: 45, loss: 0.46767228841781616\n",
      "epoch: 46, loss: 0.2600083351135254\n",
      "epoch: 47, loss: 0.30699265003204346\n",
      "epoch: 48, loss: 0.4147685468196869\n",
      "epoch: 49, loss: 0.263545960187912\n",
      "epoch: 50, loss: 0.18023967742919922\n",
      "epoch: 51, loss: 0.24714688956737518\n",
      "epoch: 52, loss: 0.11555519700050354\n",
      "epoch: 53, loss: 0.39816543459892273\n",
      "epoch: 54, loss: 0.17961883544921875\n",
      "epoch: 55, loss: 0.17364785075187683\n",
      "epoch: 56, loss: 0.35648173093795776\n",
      "epoch: 57, loss: 0.21487946808338165\n",
      "epoch: 58, loss: 0.23808208107948303\n",
      "epoch: 59, loss: 0.1852949559688568\n",
      "epoch: 60, loss: 0.3269137144088745\n",
      "epoch: 61, loss: 0.32444459199905396\n",
      "epoch: 62, loss: 0.2898232936859131\n",
      "epoch: 63, loss: 0.23656651377677917\n",
      "epoch: 64, loss: 0.2775616943836212\n",
      "epoch: 65, loss: 0.18874797224998474\n",
      "epoch: 66, loss: 0.3145853281021118\n",
      "epoch: 67, loss: 0.12515385448932648\n",
      "epoch: 68, loss: 0.13591375946998596\n",
      "epoch: 69, loss: 0.3041400909423828\n",
      "epoch: 70, loss: 0.21704672276973724\n",
      "epoch: 71, loss: 0.26503103971481323\n",
      "epoch: 72, loss: 0.10191872715950012\n",
      "epoch: 73, loss: 0.17264363169670105\n",
      "epoch: 74, loss: 0.2257654368877411\n",
      "epoch: 75, loss: 0.22019319236278534\n",
      "epoch: 76, loss: 0.14889290928840637\n",
      "epoch: 77, loss: 0.23986446857452393\n",
      "epoch: 78, loss: 0.288472056388855\n",
      "epoch: 79, loss: 0.12565967440605164\n",
      "epoch: 80, loss: 0.6083745956420898\n",
      "epoch: 81, loss: 0.23334449529647827\n",
      "epoch: 82, loss: 0.13928981125354767\n",
      "epoch: 83, loss: 0.17290310561656952\n",
      "epoch: 84, loss: 0.10782378166913986\n",
      "epoch: 85, loss: 0.16150891780853271\n",
      "epoch: 86, loss: 0.16263547539710999\n",
      "epoch: 87, loss: 0.2842863202095032\n",
      "epoch: 88, loss: 0.2731020450592041\n",
      "epoch: 89, loss: 0.30112791061401367\n",
      "epoch: 90, loss: 0.1591092348098755\n",
      "epoch: 91, loss: 0.1961473524570465\n",
      "epoch: 92, loss: 0.16685637831687927\n",
      "epoch: 93, loss: 0.13011622428894043\n",
      "epoch: 94, loss: 0.44551828503608704\n",
      "epoch: 95, loss: 0.29691460728645325\n",
      "epoch: 96, loss: 0.1655428111553192\n",
      "epoch: 97, loss: 0.11124542355537415\n",
      "epoch: 98, loss: 0.16324621438980103\n",
      "epoch: 99, loss: 0.07601649314165115\n"
     ]
    }
   ],
   "source": [
    "beta = np.exp(np.linspace(np.log(0.001), np.log(0.9), 300))\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "ddpm = ConditionalDenoisingDiffusionProbabilisticModel(\n",
    "                torch.tensor(x).float(),\n",
    "                torch.tensor(c).float(),\n",
    "                torch.tensor(beta).float(), device, batch_size=32)\n",
    "\n",
    "ddpm.learning(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict_and_execute(env, ddpm, device, n_steps, output_file = 'execution_log.csv'):\n",
    "#     # observation from gym evironment\n",
    "#     observation, _ = env.reset()\n",
    "\n",
    "#     # initialize a dataframe to log the data\n",
    "#     log_data =[]\n",
    "\n",
    "#     for step in range(n_steps):\n",
    "#         position = observation[0]\n",
    "#         velocity = observation[1]\n",
    "\n",
    "#         c_tensor = torch.tensor([[position, velocity]], dtype = torch.float32).to(device)\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             action_tensor = ddpm.sampling(c_tensor)\n",
    "        \n",
    "#         action = action_tensor.cpu().numpy().flatten()\n",
    "\n",
    "#         # execute action in the environment\n",
    "#         observation, reward, done,_,_ = env.step(action)\n",
    "\n",
    "#         env.render()\n",
    "\n",
    "#         timestamp = time.time()\n",
    "\n",
    "#         # log data into csv file\n",
    "#         log_data.append({'timestamp':timestamp, 'action':action[0], 'position':position, 'velocity': velocity})\n",
    "\n",
    "#         if done:\n",
    "#             break\n",
    "\n",
    "#         time.sleep(0.1)\n",
    "    \n",
    "#     log_df = pd.DataFrame(log_data)\n",
    "#     log_df.to_csv(output_file , index = False)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_execute(env, ddpm, device, n_steps, output_file = 'execution_log.csv'):\n",
    "    # observation from gym evironment\n",
    "    observation, _ = env.reset()\n",
    "\n",
    "    # initialize a dataframe to log the data\n",
    "    log_data =[]\n",
    "\n",
    "    position_list = []\n",
    "    velocity_list = []\n",
    "\n",
    "    for step in range(n_steps):\n",
    "        position = observation[0]\n",
    "        velocity = observation[1]\n",
    "\n",
    "        position_list.append(position)\n",
    "        velocity_list.append(velocity)\n",
    "\n",
    "        c_tensor = torch.tensor([[position, velocity]], dtype = torch.float32).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            action_tensor = ddpm.sampling(c_tensor)\n",
    "        \n",
    "        action = action_tensor.cpu().numpy().flatten()\n",
    "\n",
    "        # execute action in the environment\n",
    "        observation, reward, done,_,_ = env.step(action)\n",
    "\n",
    "        env.render()\n",
    "\n",
    "        timestamp = time.time()\n",
    "\n",
    "        # log data into csv file\n",
    "        log_data.append({'timestamp':timestamp, 'action':action[0], 'position':position, 'velocity': velocity})\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "        time.sleep(0.1)\n",
    "    \n",
    "    log_df = pd.DataFrame(log_data)\n",
    "    log_df.to_csv(output_file , index = False)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gym' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     env \u001b[38;5;241m=\u001b[39m \u001b[43mgym\u001b[49m\u001b[38;5;241m.\u001b[39mmake(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMountainCarContinuous-v0\u001b[39m\u001b[38;5;124m'\u001b[39m, render_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m     ddpm \u001b[38;5;241m=\u001b[39m ConditionalDenoisingDiffusionProbabilisticModel(torch\u001b[38;5;241m.\u001b[39mtensor(x)\u001b[38;5;241m.\u001b[39mfloat(),\n\u001b[0;32m      4\u001b[0m                 torch\u001b[38;5;241m.\u001b[39mtensor(c)\u001b[38;5;241m.\u001b[39mfloat(),\n\u001b[0;32m      5\u001b[0m                 torch\u001b[38;5;241m.\u001b[39mtensor(beta)\u001b[38;5;241m.\u001b[39mfloat(), device, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m      6\u001b[0m     predict_and_execute(env,ddpm, device, n_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gym' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    env = gym.make('MountainCarContinuous-v0', render_mode=\"human\")\n",
    "    ddpm = ConditionalDenoisingDiffusionProbabilisticModel(torch.tensor(x).float(),\n",
    "                torch.tensor(c).float(),\n",
    "                torch.tensor(beta).float(), device, batch_size=32)\n",
    "    predict_and_execute(env,ddpm, device, n_steps=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dif_aug_cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
